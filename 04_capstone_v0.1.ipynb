{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Learning Capstone:\n",
    "\n",
    "For this project you'll dig into a large amount of text and apply most of what you've covered in this unit and in the course so far.\n",
    "\n",
    "First, pick a set of texts. This can be either a series of novels, chapters, or articles. Anything you'd like. It just has to have multiple entries of varying characteristics. At least 100 should be good. There should also be at least 10 different authors, but try to keep the texts related (either all on the same topic of from the same branch of literature - something to make classification a bit more difficult than obviously different subjects).\n",
    "\n",
    "This capstone can be an extension of your NLP challenge if you wish to use the same corpus. If you found problems with that data set that limited your analysis, however, it may be worth using what you learned to choose a new corpus. Reserve 25% of your corpus as a test set.\n",
    "\n",
    "The first technique is to create a series of clusters. Try several techniques and pick the one you think best represents your data. Make sure there is a narrative and reasoning around why you have chosen the given clusters. Are authors consistently grouped into the same cluster?\n",
    "\n",
    "Next, perform some unsupervised feature generation and selection using the techniques covered in this unit and elsewhere in the course. Using those features then build models to attempt to classify your texts by author. Try different permutations of unsupervised and supervised techniques to see which combinations have the best performance.\n",
    "\n",
    "Lastly return to your holdout group. Does your clustering on those members perform as you'd expect? Have your clusters remained stable or changed dramatically? What about your model? Is it's performance consistent?\n",
    "\n",
    "If there is a divergence in the relative stability of your model and your clusters, delve into why.\n",
    "\n",
    "Your end result should be a write up of how clustering and modeling compare for classifying your texts. What are the advantages of each? Why would you want to use one over the other? Approximately 3-5 pages is a good length for your write up, and remember to include visuals to help tell your story!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "import nltk\n",
    "import spacy\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('reuters')\n",
    "from nltk.corpus import reuters, stopwords\n",
    "#print(reuters.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7769\n",
      "3019\n"
     ]
    }
   ],
   "source": [
    "#each file is pre-labeled for train (~73%) and test (remaining 27%)\n",
    "train_files = list(filter(lambda x: x.startswith('training'), reuters.fileids()))\n",
    "test_files = list(filter(lambda x: x.startswith('test'), reuters.fileids()))\n",
    "\n",
    "print(len(train_files))\n",
    "print(len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAHIA COCOA REVIEW\n",
      "  Showers continued throughout the week in\n",
      "  the Bahia cocoa zone, alleviating th\n"
     ]
    }
   ],
   "source": [
    "#see what this data looks like\n",
    "train_raw = reuters.raw(train_files)\n",
    "test_raw = reuters.raw(test_files)\n",
    "\n",
    "print(train_raw[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['training/1',\n",
       " 'training/10',\n",
       " 'training/100',\n",
       " 'training/1000',\n",
       " 'training/10000']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1253696\n",
      "6478471\n",
      "467205\n",
      "2368382\n"
     ]
    }
   ],
   "source": [
    "print(len(reuters.words(train_files)))\n",
    "print(len(reuters.raw(train_files)))\n",
    "print(len(reuters.words(test_files)))\n",
    "print(len(reuters.raw(test_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text cleaning function\n",
    "def text_cleaner(text):\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub('[\\[].*?[\\]]','',text)\n",
    "    text = text.lower()\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7769 train files; data shape is (6577, 3)\n",
      "articles eliminated: 1192\n",
      "\n",
      "dataframe head: \n",
      "       category          fileid  \\\n",
      "0         cocoa      training/1   \n",
      "1           acq     training/10   \n",
      "2  money-supply    training/100   \n",
      "3           acq   training/1000   \n",
      "4          earn  training/10000   \n",
      "\n",
      "                                                text  \n",
      "0  bahia cocoa review showers continued throughou...  \n",
      "1  computer terminal systems &lt;cpml> completes ...  \n",
      "2  n.z. trading bank deposit growth rises slightl...  \n",
      "3  national amusements again ups viacom &lt;via> ...  \n",
      "4  rogers &lt;rog> sees 1st qtr net up significan...  \n",
      "\n",
      "3019 test files; data shape is (2583, 3)\n",
      "articles eliminated: 436\n",
      "\n",
      "dataframe head: \n",
      "  category      fileid                                               text\n",
      "0    trade  test/14826  asian exporters fear damage from u.s.-japan ri...\n",
      "1    grain  test/14828  china daily says vermin eat 7-12 pct grain sto...\n",
      "2     ship  test/14839  australian foreign ship ban ends but nsw ports...\n",
      "3     gold  test/14842  western mining to open new gold mine in austra...\n",
      "4      acq  test/14843  sumitomo bank aims at quick recovery from merg...\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.DataFrame()\n",
    "for file in train_files:\n",
    "    if len(reuters.categories(file)) == 1:\n",
    "        train_df = train_df.append({\n",
    "            'category':''.join(reuters.categories(file)),\n",
    "            'fileid':file,\n",
    "            'text':text_cleaner(reuters.raw([file]))}, ignore_index=True)\n",
    "print('\\n{} train files; data shape is {}'.format(len(train_files), train_df.shape))\n",
    "print('articles eliminated: {}\\n'.format(len(train_files) - len(train_df)))\n",
    "print('dataframe head: \\n{}'.format(train_df.head()))\n",
    "\n",
    "test_df = pd.DataFrame()\n",
    "for file in test_files:\n",
    "    if len(reuters.categories(file)) == 1:\n",
    "        test_df = test_df.append({\n",
    "            'category':''.join(reuters.categories(file)),\n",
    "            'fileid':file,\n",
    "            'text':text_cleaner(reuters.raw(file))}, ignore_index=True)\n",
    "print('\\n{} test files; data shape is {}'.format(len(test_files), test_df.shape))\n",
    "print('articles eliminated: {}\\n'.format(len(test_files) - len(test_df)))\n",
    "print('dataframe head: \\n{}'.format(test_df.head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "earn        2840\n",
      "acq         1596\n",
      "crude        253\n",
      "trade        250\n",
      "money-fx     222\n",
      "Name: category, dtype: int64\n",
      "58\n",
      "earn        1083\n",
      "acq          696\n",
      "crude        121\n",
      "money-fx      87\n",
      "interest      81\n",
      "Name: category, dtype: int64\n",
      "59\n"
     ]
    }
   ],
   "source": [
    "print(train_df['category'].value_counts().head())\n",
    "print(train_df['category'].nunique())\n",
    "\n",
    "print(test_df['category'].value_counts().head())\n",
    "print(test_df['category'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n",
      "59\n",
      "90\n",
      "\n",
      "7 cats in test not in train:\n",
      "['groundnut', 'rice', 'yen', 'hog', 'naphtha', 'propane', 'coconut']\n",
      "\n",
      "6 cats in train not in test:\n",
      "['oilseed', 'nzdlr', 'silver', 'dmk', 'l-cattle', 'rand']\n",
      "\n",
      "25 cats not in train or test:\n",
      "['corn', 'soy-oil', 'palladium', 'copra-cake', 'sun-oil', 'palm-oil', 'wheat', 'barley', 'sunseed', 'sorghum', 'nkr', 'cotton-oil', 'sun-meal', 'castor-oil', 'groundnut-oil', 'soybean', 'palmkernel', 'oat', 'rape-oil', 'lin-oil', 'soy-meal', 'rye', 'rapeseed', 'dfl', 'coconut-oil']\n"
     ]
    }
   ],
   "source": [
    "#does the test set contain any categories that the train set doesn't?\n",
    "print(train_df['category'].nunique())\n",
    "print(test_df['category'].nunique())\n",
    "print(len(reuters.categories()))\n",
    "\n",
    "train_cats = train_df['category'].unique()\n",
    "test_cats = test_df['category'].unique()\n",
    "\n",
    "print('\\n{} cats in test not in train:\\n{}'.format(\n",
    "    len([x for x in test_cats if x not in train_cats]),\n",
    "    [x for x in test_cats if x not in train_cats]))\n",
    "print('\\n{} cats in train not in test:\\n{}'.format(\n",
    "    len([x for x in train_cats if x not in test_cats]),\n",
    "    [x for x in train_cats if x not in test_cats]))\n",
    "print('\\n{} cats not in train or test:\\n{}'.format(\n",
    "    len(list(set(reuters.categories()) - set(train_cats) - set(test_cats))),\n",
    "    list(set(reuters.categories()) - set(train_cats) - set(test_cats))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this should print True: True\n",
      "65 categories accounted for\n"
     ]
    }
   ],
   "source": [
    "#combine train/test file dfs due to category inconsistencies\n",
    "#use train_test_split for train/test sets\n",
    "\n",
    "#concat dfs and make sure it worked\n",
    "reuters_df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "print('this should print True: {}'.format(\n",
    "    len(train_df) + len(test_df) == len(reuters_df)))\n",
    "print('{} categories accounted for'.format(reuters_df['category'].nunique()))\n",
    "\n",
    "#set data/target & train/test sets\n",
    "X = reuters_df['text']\n",
    "y = reuters_df['category']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf-idf feature generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features: 9886\n",
      "original sentence: island telephone share split approved &lt;island telephone co ltd> said the previously announced two-for-one common share split was approved by shareholders at the annual meeting.\n",
      "tf_idf vector: {'lawson': 0.44068087581349996, 'says': 0.26177554630223016, 'sterling': 0.37847288654809347, 'target': 0.33260923867694914, 'comments': 0.4226293968497558, 'insignificant': 0.5520758013747038}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.5,\n",
    "                             min_df = 3,\n",
    "                             stop_words='english',\n",
    "                             lowercase=False,\n",
    "                             use_idf=True,\n",
    "                             norm=u'l2',\n",
    "                             smooth_idf=True)\n",
    "\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "print('number of features: {}'.format(X_train_tfidf.get_shape()[1]))\n",
    "\n",
    "#extract features & tfidf scores\n",
    "X_train_tfidf_csr = X_train_tfidf.tocsr()\n",
    "n = X_train_tfidf_csr.shape[0]\n",
    "tfidf_dicts = [{} for _ in range(0,n)]\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i, j in zip(*X_train_tfidf_csr.nonzero()):\n",
    "    tfidf_dicts[i][terms[j]] = X_train_tfidf_csr[i,j]\n",
    "\n",
    "#since log base 2 of 1 = 0, tf-idf of 0 means word was present once\n",
    "print('original sentence:', X_train[5])\n",
    "print('tf_idf vector:', tfidf_dicts[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "idea: use clustering to group categories, then use the best of these groupings for classification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize, Normalizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "X_train_norm = normalize(X_train_tfidf)\n",
    "X_train_svd = TruncatedSVD(2).fit_transform(X_train_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adj rand score: 0.0987751213493789\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.metrics import adjusted_rand_score, silhouette_score\n",
    "\n",
    "y_pred = KMeans(n_clusters=65).fit_predict(X_train_norm)\n",
    "print('adj rand score: {}'.format(adjusted_rand_score(y_train, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization with Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "X_train_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conform with spacys character limit\n",
    "train_substrings = [train[i:i+999999] for i in range(0, len(train), 999999)]\n",
    "test_substrings = [test[i:i+999999] for i in range(0, len(test), 999999)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train0 = train_substrings[0]\n",
    "train1 = train_substrings[1]\n",
    "train2 = train_substrings[2]\n",
    "train3 = train_substrings[3]\n",
    "train4 = train_substrings[4]\n",
    "train5 = train_substrings[5]\n",
    "train6 = train_substrings[6]\n",
    "\n",
    "test0 = test_substrings[0]\n",
    "test1 = test_substrings[1]\n",
    "test2 = test_substrings[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "\n",
    "start = time.clock()\n",
    "train0_doc = nlp(train0)\n",
    "print(time.clock() - start)\n",
    "train1_doc = nlp(train1)\n",
    "print(time.clock() - start)\n",
    "train2_doc = nlp(train2)\n",
    "print(time.clock() - start)\n",
    "train3_doc = nlp(train3)\n",
    "print(time.clock() - start)\n",
    "train4_doc = nlp(train4)\n",
    "print(time.clock() - start)\n",
    "train5_doc = nlp(train5)\n",
    "print(time.clock() - start)\n",
    "train6_doc = nlp(train6)\n",
    "print(time.clock() - start)\n",
    "test0_doc = nlp(test0)\n",
    "print(time.clock() - start)\n",
    "test1_doc = nlp(test1)\n",
    "print(time.clock() - start)\n",
    "test2_doc = nlp(test2)\n",
    "print(time.clock() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_docs = [train0_doc, train1_doc, train2_doc, train3_doc, train4_doc, train5_doc, train6_doc]\n",
    "train_tokens = []\n",
    "for doc in train_docs:\n",
    "    for token in doc:\n",
    "        train_tokens.append(token)\n",
    "        \n",
    "test_docs = [test0_doc, test1_doc, test2_doc]\n",
    "test_tokens = []\n",
    "for doc in test_docs:\n",
    "    for token in doc:\n",
    "        test_tokens.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure this worked\n",
    "print(len(train_tokens))\n",
    "print(len(train0_doc) + len(train1_doc) + len(train2_doc) + len(train3_doc)\n",
    "      + len(train4_doc) + len(train5_doc) + len(train6_doc))\n",
    "\n",
    "print(len(test_tokens))\n",
    "print(len(test0_doc) + len(test1_doc) + len(test2_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
